---
layout:     post                    # 使用的布局（不需要改）
title:      人工智能导论笔记【搜索II】              # 标题 
subtitle:   Beyond Classical Search #副标题
date:       2020-04-04         # 时间
author:     Alkane                      # 作者
header-img: img/ai_2020.jpg    #这篇文章标题背景图片
catalog: true                       # 是否归档
tags:                               #标签
    - 人工智能
---

# Beyond Classical Search

之前我已经写过一篇介绍搜索的博客,其中主要包括了:

- Uninformed Search

  - DFS
  - BFS
  - IDFS
  - UCS

- Informed Search

  - A*
  - Greddy Search

但是在我们之前的搜索中,都会出现这样的问题,也就是我们对于环境是充分了解的，也就是我们知道目前所处的状态,也知道如果我采取这样的行动会得到什么其他的状态。

今天我们就要介绍一些适用于更加广泛情形的算法，主要包含:

- Local Search
  - Hill climbing(steepest desent)
  - Simulated annealing
  - Local beam search
  - Genetic algorithms

- Nondeterminstic Search
  - AND-OR-Search
- Online Search
  - LRTA*

我们首先会介绍只关注局部信息的搜索，接着我们会讨论如果动作不能确定出状态情况下的搜索，再来我们讨论不同程度的观察对搜索的影响和如何搜索，最后我们会对完全未知的世界探索做Online Search.

## Local Search

所谓的Local search就是在状态空间中进行纯粹的局部搜索,我们在这里只关注状态，而不关注从初始状态到该状态的代价,可以理解为这样:

![](https://pic.downk.cc/item/5e8802b1504f4bcb046a6516.jpg)

我们关注的只是能否到达更优的状态,至于怎么到达,从那里来不是我们在意的。

### Hill climbing

如果已经学过梯度下降法，就很容易发现这是同样的思想,也就是从当前位置出发,选择当前位置邻居状态中相对于当前状态最优的一个,如果没有比现在状态更优的解那么算法停止。

算法的伪码如下:

![](https://pic.downk.cc/item/5e88229d504f4bcb0487ed30.jpg)

值得注意的是,爬山法通常可以走到局部最优解(Local optimal),但不能对最优解做出任何保证。 

比如在上图中的一块平地上，四周的值均相等,那么爬山法就会在这里退出。可能的解决方法是当周围的点不比此时的状态更差时仍然可以选取周围的点,但是要注意给出终止条件,比如100步之内要停下来,防止出现在平地上游荡的现象发生。

另一种改进是每次的初始状态都随机,然后使用爬山法,这样可以保证当尝试足够多次以后一定能得到最优解，原因是每次爬山法都有一个非零的概率得到最优解,那么尝试足够多次以后就能保证得到的是最优解了。



### Simulated annealing

爬山法有一个执念，每次都要选取比当前点更优的点，这虽然上进，但容易捡了芝麻丢西瓜。另一种常见的搜索叫做随机游走(random walk),也就是字面意义上的random，每次都随机挑一个方向走，如果比现在的好就转移。

模拟退火法就是结合上面两种算法的产物，它对于避免陷入局部最优解有不错的效果。

![](https://pic.downk.cc/item/5e8825c0504f4bcb048ac60f.jpg)

我们把当前节点的值与周围节点的值的插值作为$\Delta E$,并用一个函数$schedule(t)=T$,来作为当前算法的温度,当周围节点要优于当前节点的时候我们直接选择周围的那个节点,但是当当前节点已经是局部最优时，我们也要确保它有一定的机率转移到其他的点，因为此时的$\Delta E\lt 0$,所以$e^{\Delta\over T}$，就是一个介于$[0,1)$的值，我们把它作为转移的概率，按照这个概率来脱离当前状态。

模拟退火法中比较重要的参数就是温度函数$schedule(t)$，如果温度一直很高，比如温度一直趋于正无穷,那么每一次转移的概率都接近于1，算法就退化成随机游走。相反，如果温度一直很低，那么算法就退化成爬山法。

### Local beam search

模拟退火法并不能保证得到最优解,一个有效提高模拟退火法效率的方法是采用Local beam search。

思想是这样:同时并行地用多个模拟退火法，每次选取其中k个最优的状态作为下一次模拟退火法的初始状态，如此下去，显然当一个模拟退火过程找到最优解后，很快所有的状态都会趋于这个最优解。

当然，为了避免同样的局部最优解的情况，还可以用Stocastic Local beam search，也就是每次选取的不是k个最优的，而是按照状态作为分布，采k次样来作为下一次的初始状态。

### Genetic algorithms

遗传算法我想大多数人都了解它的原理，事实上这也是Local beam search的一种变形，只是它生成下一轮状态的方法不是抽样，而是对已有状态的组合(combination).

但是遗传算法首先要对状态们做编码(encoding),也就是相当于给每一个状态一个DNA链条来表征它，接着对已有状态的重组就是选取不同的DNA的不同片段来组成新的状态。

通常的遗传算法还会加上变异的部分，也就是给重组后的DNA上随机挑选位置来进行突变，如果用二进制来编码的话，那么也就相当于0变成1，1变成0.

下面的算法是组合DNA的。

![](https://pic.downk.cc/item/5e882afe504f4bcb048f41e9.jpg)

下面就是遗传算法:

![](https://pic.downk.cc/item/5e882b2a504f4bcb048f6fb6.jpg)



## Searching with Nondeterministic Actions

上面我们主要关注的是只使用局部信息搜索得到最优解或是较优解的办法，下面我们来讨论当考虑不确定性时搜索的方法。

小明每天都要上学，他沿着自己家朝着学校走，理论上小明选择向东走这个动作真的可以朝东边走，但是今天小明的小脑出了问题，他选择向东走这个动作的时候，有50%的概率停在原地，30%的概率向东走，20%的概率坐下。

虽然我们面对的真实世界没有上面这个例子这么夸张，但还是会有很多时候动作转移状态具有不确定性。

<img src="https://pic.downk.cc/item/5e883358504f4bcb0496b03f.jpg" style="zoom:50%;" />

上图是一个吸尘器的例子，这个吸尘器有三种动作可以选择{吸,向左,向右}.

而吸尘器的目标是把这两个房间打扫干净。

但是这个吸尘器有点小毛病,它选择做吸这个动作的时候，如果当前房间是有灰尘的，有可能会把隔壁房间的灰尘洗干净，当当前房间是干净的时候则有可能把吸进去的灰尘吐出来。

可以看出来上面的搜索树其实分成两种节点，比如根节点这样的节点就可以选择不同的动作来做状态的转移，这样的节点称作**OR-Node**,而另一种节点就像是根节点的左儿子这样的节点,由于选择的动作是具有不确定性而得到的不确定的状态，我们称作**AND-Node**.

之所以叫**AND-Node**,是因为我们要保证不管该节点的状态究竟是哪一个，我们都有办法通过一系列的动作转移到Goal节点，而**OR-Node**是因为我们只需要选择可能的动作中的一支来转移到Goal节点。

![](https://pic.downk.cc/item/5e883738504f4bcb049b17fb.jpg)

上图就是AND-OR-SEARCH的算法伪码，可以看出这是一种循环调用关系的算法。

可以看出在具有不确定性状态转移的时候,我们就很难快速的得到问题的解。

## Searching with Partial Observations

首先，我们讨论一下瞎子走路的可行性，也就是当你对周遭世界的状态，甚至你自己处于什么状态都不清楚的时候，如何转移到你的目标状态。

### No observation

虽然我们是瞎子，不能清楚的得知自己所处的状态，但我们却可以给出我们当前所处的状态属于什么样的集合，把所有可能处于的状态构成的集合称为Belif state.

显然当我们处于确定性的世界时，采取什么样的动作就会得到什么样的结果，那当我们做出action后，就可以减小不确定性，也就是把belif state的大小变小。

当我们所处的belif state中只有goal，或者全部都是goal时，我们称此时我们到达goal。

下面就是一个瞎子吸尘器的状态转移图。

<img src="https://pic.downk.cc/item/5e883b32504f4bcb04a0b9c8.jpg" style="zoom:50%;" />

但是，如果我们所处的世界是上面提到的具有不确定性的，每次转移都不能保证一定到达什么状态的世界，情况就变得复杂起来，因为完全有可能在采取action的时候把belif state变大，这就难以保证我们可以到达goal了，在这样的情况下，我们可以做的就是让瞎子睁眼。

### Searching with observations

这里的思想就是很简单，通过观察周遭环境来减少不确定性,把belif state中不可能是当前状态的元素移走，来shrink我们的belif state.

## Online Search

好，下面进入我们最后一个话题Online Search.

Online Search 和我们上面提到的瞎子走路很像,不过特别的是Online Search对于当前的状态空间一无所知，对这个动作能得到什么状态也是一无所知。

我们能做的就是走一步看一步。

![](https://pic.downk.cc/item/5e884158504f4bcb04a8ad5a.jpg)

理论上可以证明,当我们处于什么都不知道的情况时，是很有可能进去最糟糕的情况的，正如上图的路线，由于什么都不知道，我们往往走了最远的路而不自知。

如果我们可以保证每个动作都可逆的话，我们理论上能够先探索所有的状态，得到这个世界的地图，然后就可以使用各式各样的算法来解决这些问题。

下面就是一个在上述前提下使用DFS算法求解问题的伪代码

![](https://pic.downk.cc/item/5e8842aa504f4bcb04aa7057.jpg)

在最差的情况下就是遍历所有可能的状态，这样的算法时间上是指数级的复杂度，空间上也要求线性的复杂度。

我们还可以使用Online的爬山法或是模拟退火法，当然前提都是动作可逆。

最后介绍A*算法在Online search中的变形:

A*算法最精髓的地方就是结合了过去和未来两部分，即考虑已经走过的路(g(s))，又能放眼未来(h(s)),而在Online search中，想要放眼未来就得不断地更新h(s).

![](https://pic.downk.cc/item/5e8843ed504f4bcb04ac1362.jpg)

可以看出,我们的LRTA*算法会在搜索过程中慢慢的修正之前的启发函数,使其更加符合实际情况。

LRTA*最大的缺点就是对空间的复杂度过高,需要记录所有的action和状态的对应关系。

## Summary

搜索这个部分是很讲究的，我们有限的时间重点要掌握思想，而不能局限于算法，抑或是具体的实现，要灵活的运用知识。

## Reference

[BAIR](https://inst.eecs.berkeley.edu/~cs188/sp20/)