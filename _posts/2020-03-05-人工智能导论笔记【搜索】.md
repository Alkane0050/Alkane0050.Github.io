---
layout:     post                    # 使用的布局（不需要改）
title:      人工智能导论笔记【搜索】              # 标题 
subtitle:   一种求解问题的方式 #副标题
date:       2020-03-05          # 时间
author:     Alkane                      # 作者
header-img: img/ai_2020.jpg    #这篇文章标题背景图片
catalog: true                       # 是否归档
tags:                               #标签
    - 人工智能

---



# 搜索

## 写在前面的话

人工智能导论，讲的是一般性的方法、理论，不同于深度学习那样具体，但是会有很多有趣的东西，我很期待这门课给我带来的惊喜，老实说我不喜欢学校安排的单片机、软件工程这些课，一个是老师讲课不甚有趣，另一个就是我本人更喜欢理论一些的东西，有一种高屋建筑的感觉。

给自己的期望是一到两个星期写一篇这样的博客，整理记录自己的学习，也方便日后考研用。

## 背景知识介绍

### Agents

AI中的一个核心问题就是如何构造一个理想个体(rational agent),可以在面对所处的不同环境(enviroment)采取不同的动作(actions)来得到最佳的回馈.

我们在接下来的很多主题中都会借由agent的视角来看待问题。

### State Space & Search Problems

为了创造出一个理想的agent,我们需要从数学的角度来描述当前agent所处环境，这样才可以对agent后续的动作做出更好的选择。

下面是我们在搜索问题中会用到的一些定义

- s: 起始状态
- Action(s):状态s下允许的动作集合
- Cost(s,a):动作a的代价
- Succ(s,a):状态s执行动作a得到的状态(有可能是集合)
- IsGoal(s):状态s是否是目标状态

### State Space Graphs & Search Trees

一般的搜索问题都可以看成是在状态空间表示的图上进行搜索，下面我们来对什么是State Space Graphs做更深入的了解

我们知道,一个图是由节点(node)和边(edge)组成,不同的节点之间有边相连，有时候这些边还可能是带有权重的，也有可能是有向的，这要取决于不同的图的特性。

> A **state space graph** is constructed with states repre-senting nodes, with directed edges existing from a state to its successors.  These edges represent actions,and any associated weights represent the cost of performing the corresponding action

一个状态空间图(State Space Graph)是:

- 由不同的状态空间中的状态(state)组成其节点
- 节点之间的边表示动作(action),一条边由自身指向其后继(successor)
- 边上的权重表示这个动作的代价(cost)

通常来说，我们遇到的问题的状态空间是十分大的(比如围棋的状态空间)，一般无法直接画出来或是存储在计算机中，但是这并不影响我们很好的解决问题，得到最优解。

搜索树(Search Tree)是一个用于刻画搜索过程的树，具体的定义我们没必要给出，下面这张图就能说明搜索树是什么。

![](https://pic.downk.cc/item/5e60c55d98271cb2b89e2fd0.jpg)

我们这样再来看什么是搜索树:

- 根节点: 起始状态
- 叶节点: 目标状态
- 每条边表示一个动作
- 边上的权值表示代价
- 根节点到叶节点的路径表示一个解
- 最短路径表示最优解

## Uninformed Search

首先我们来了解一下没有信息的搜索(Uninformed Search)，也就是说，在进行搜索的过程中时，我们并不知道外界的相关信息(或者说不考虑除了节点本身以外的其他信息，如边的权值等)。

用统一的算法描述是这样的:

![](https://pic.downk.cc/item/5e60d43898271cb2b8a93c0c.jpg)

从算法的描述我们可以看出,这样的搜索只用到了状态空间表示图中的拓扑结构,也就是说只用到了这个状态与哪些状态相连了，而这个状态到其他状态需要付出的代价则不在我们的考虑之内(因为我们的搜索是uninformed search).

上面提到的搜索不像是算法，因为它实际上没法编程实现，更像是一类算法的概括，是方法论的一种。下面我们来看一下在这样的方法论指导下的几个具体的算法。

- 深度优先搜索(Deep First Search)
- 广度优先搜索(Breadth First Search)
- 统一代价搜索(Uniform Cost Search)

我们还会从以下几个角度来评价不同的搜索算法

- 完备性(completeness): 也就是这个算法是否能在有限时间内得到解
- 最优性(optimality):也就是得到的解是否是最优解
- 复杂度(complexity):包括时间复杂度与空间复杂度

### 深度优先搜索

> 深度优先搜索(DFS)是一种每次都选取深度最深的节点进行搜索的搜索策略

在深度优先搜索中，每次选取节点我们优先选取当前节点的子节点，若当前节点无子节点且当前节点不为目标节点，我们就回溯到上一层节点，从其子节点中选取一个未访问过的进行访问。

用图表示是:

![](https://pic.downk.cc/item/5e60f10498271cb2b8ba8222.jpg)

通常我们用栈这个数据结构来实现DFS.

简单的评价一下DFS:

- 不完备：你有可能找不到解，如果你的运气不够好，走了一条无底路的话:(
- 不最佳: 一般地，你会在最左边的最优解中退出，所以DFS很可能得不到最优解 :(
- 时间复杂度: 最差情况，DFS可能需要遍历所有节点，这可能需要耗费$O(b^m)$的时间
- 空间复杂度: 最差情况, DFS需要保留m层节点，也就是$O(bm)$的空间





### 广度优先搜索

> 广度优先搜索(BFS)是一种每次都选取深度最浅的节点以获取更大的广度的策略

在广度优先搜索中我们每次搜索都要先遍历当前节点所在层的所有节点，接着再遍历下一层。

用图表示是:

![](https://pic.downk.cc/item/5e60f38998271cb2b8bc3104.jpg)



而我们通常用队列来实现BFS.

评价:

- 完备性: 如果存在最优解,那么BFS一定可以得到最优解
- 最佳性:BFS得到的解一定是最优解
- 时间复杂度: $O(b^s)$，s为最优解所在的深度
- 空间复杂度:$O(b^s)$

### 迭代加深的深度优先搜索

广度优先搜索看起来比深度优先要好很多，但是在空间复杂度方面，广度优先搜索成为一个开销很大的算法，为了结合二者的优势，可以使用一个折衷的办法，迭代加深的DFS.

过程类似这样:

- DFS(深度=1)
- DFS(深度=2)
- DFS(深度=3)
- …

这样我们就可以用较小的空间复杂度来得到类似广度优先搜索的结果了。

### 等代价搜索

> 等代价搜索(UCS)是一种每次都选取距离开始节点距离最近的节点进行扩展的策略

在等代价搜索中，每次我们都选取目前为止从开始的点到当前点的代价最小的点。

![](https://pic.downk.cc/item/5e60fa8e98271cb2b8c017a0.jpg)

这里需要特别说明一下，之前的DFS,BFS我们其实都默认每一次动作的代价都是相同的，这样才能保证BFS得到的是最优解，而当不同的节点之间的代价不同时，BFS,DFS都不能得到最优解，而UCS可以，因为它保证了不会存在比当前路径更短的路径。

UCS通常用优先队列来实现

下面评价一下:

- 完备性:显然
- 最佳性:容易证明
- 时间复杂度:记最优路径的cost为$C^*$,俩个节点之间的最小cost为$\epsilon$,则时间复杂度为: $O(b^{C^*/\epsilon})$ 
- 空间复杂度:$O(b^{C^*/\epsilon})$

## Informed Search

我们之前介绍了UCS，看上去UCS很好，能够保证得到最优解。但是UCS存在一个问题，就是它每次探索节点的时候都要等可能的探索，因为你不知道哪个点是最优路径上的点而哪个点不是，换句话说，UCS的速度比较慢，开销比较大。

有没有可能提高速度呢?

我们将在这一节介绍启发式搜索，或者叫有信息的搜索(Informed Search).

### Heuristic

简要介绍一下什么是启发式(Heuristic).

- 一个衡量当前状态到目标状态之间的函数。
- 通常是在特定的搜索问题中设计出来的。(具体问题具体分析，矛盾的特殊性).

用启发式作为我们搜索的前提信息，就相当于看着地图走迷宫，速度当然要快于自己摸瞎。



### Greedy Search

什么是贪心搜索其实不用我细说，就是每次搜索都选目前所看到的最优解，如此而已。

![](https://pic.downk.cc/item/5e61b76698271cb2b8ffb9d3.jpg)

需要说明的是，贪心搜索衡量一个目标是否比其他目标更优的依据就是我们自行设计的启发式函数，所以不同的问题，设计不同的启发式函数就很可能得到不一样的结果。

一般来说，贪心搜索都只能得到局部最优解，更差的情况是得不到解。

贪心搜索的最大优点就是速度快，一般很快就能得到一个解。



### $A^*$

UCS算法能得到最优解但是慢，Greedy能快速得到解但未必最优。

结合二者的优势会怎么样?

![](https://pic.downk.cc/item/5e61bace98271cb2b8011bde.jpg)

先来看一个例子：

![](https://pic.downk.cc/item/5e61c39498271cb2b803e3e6.jpg)

上图的$g$表示走到当前节点需要花费的代价，注意这里的代价是真实的代价，也就是路径上的权重之和。

UCS搜索每次选取节点的依据是g，也就是说，选取当前队列中的g最小的点，将其出队，并将其子节点入队。

在上面这张图中，UCS搜索的次序为:

> S->a->b,d,e->c->G

h表示启发式函数，在我们这个图的例子里，h表示该点到G的距离。

Greedy搜索选取节点的依据是h，也就是选取当前队列中h最小的点，将其出队，并将其子节点入队。

Greedy搜索的次序为:

> S->a->b,d,e->d’->G



$A^*$的主要思想就是将g和h结合起来，也就是用f=g+h来作为其搜索时的依据。

这里的思想是: g表示到目前为止，搜索到这个节点的路径上所需要付出的代价，而h作为一种对这个节点到目标节点的路径需要付出的代价的estimate，如果我们知道了每一个节点到目标节点真实的代价的话，其实也就没必要做搜索了，直接沿着最小代价的路径走就是了，而实际问题中往往并不能如愿，所以我们用一个启发式函数来作为对真实距离的一种预测。



从上面的描述我们可以了解到，$A^*$算法的关键应该就在于h的选择，因为g是一个客观的值，而h是我们人可以选择的，再观察还可以发现:

如果让h=0，$A^*$算法就是UCS算法，而UCS算法可以保证解的最优性，似乎暗示着要让$A^*$得到的解最优，我们的h不能太大？



要说明$A^*$算法的最优性，先来看个$A^*$算法没有得到最优解的例子。



#### 例子

![](https://pic.downk.cc/item/5e61f04898271cb2b811564f.jpg)

这个图里的搜索路径是:

>  S->G

因为从S到A的g+h=2+6=8，而S直接到G的g+h=6+0=6.

但明显这里的最优路径应该是S->A->G,我们发现，这里$A^*$出错的原因在于:

**h取的大了！**

它过分估计了当前点到目标点的距离。

下面给出几个关于启发式函数性质的定义，这有利于我们进一步说明$A^*$算法的最优性。

#### 可接受的(Admissible)

如果一个启发式函数满足下面的性质我们就叫它是admissible的。

> 对于任意的节点n,都有$0\le h(n)\le h^*(n)$.
>
> 这里的$h^*(n)$表示的是节点n到目标节点的真实距离(注意不是欧式距离或者曼哈顿距离，而是图上的路径长度的和)



我们来简单的证明一下，如果在$A^*$算法中，采用的启发式函数h是可接受的，那么得到的解一定是最优解。

#### 正确性的证明

![](https://pic.downk.cc/item/5e61f66798271cb2b8135ee6.jpg)

首先设A是最优点，B是次优点。(虽然在状态上A,B相同，但是从搜索树的角度来看，这两者是不一样的，因为走过的路径不同),我们要证明的是$A^*$一定在走到B之前先走到A.

> proof:
>
> 设在某个时刻,我们搜索的队列中已经包含了B，这个时候我们可以断定，要么A已经被移除队列(即发现最优解)，要么此时的队列中有A或A的祖先。
>
> 不妨设A的祖先n就在此时的搜索队列中，我们需要说明的是算法会首先搜索n而不是B,要保证这一点也就是说明f(n)<f(B).
>
> f(n) = g(n) + h(n).
>
> f(B) = g(B) + h(B).
>
> ![](https://pic.downk.cc/item/5e61fa9598271cb2b814d215.jpg)
>
> f(n) < g(A) = f(A). 这是因为h(n)是可接受的，也就是h(n)要小于等于实际从n到A要走过的距离。
>
> 下面我们证明f(A)<f(B).
>
> f(A) = g(A) + h(A), 但是h(A) = 0,所以f(A) = g(A).
>
> 同样的,f(B) = g(B).
>
> 因为A是最优点,B是次优点,所以f(A)<f(B).
>
> 所以f(n)<f(A)<f(B).
>
> 所以我们在搜索的时候会先搜索节点n,这样就能保证节点A在节点B之前被出队。
>
> 也就是算法具有最优性.

### Graph Search

前面提到的所有搜索都是基于搜索树来进行的，但是在实际中，我们会遇到一个节点多次访问的情况，如下图:

![](https://pic.downk.cc/item/5e6210bf98271cb2b81b4d47.jpg)

在算法设计里，如果出现这样的冗余情况，一个好的算法是要能尽量避免这种情况的发生的。

而有效的方法就是采用图搜索。

![](https://pic.downk.cc/item/5e62119598271cb2b81b91dd.jpg)

这里与树搜索不一样在于，每次我们考虑搜索一个节点的时候，都需要判断之前是否已经搜索过了，这就需要我们准备一个集合用于存放已经搜索过的点。

问题来了，之前我们提到的算法还能用于图搜索吗？

看下面这个$A^*$算法的例子：

![](https://pic.downk.cc/item/5e62131298271cb2b81bf2b2.jpg)

如果是用树搜索，我们是一定可以得到正确答案的，但如果采用了不走重复节点的图搜索，就会出现这样的情况:

> S -> B -> C -> G
>
> ![](https://pic.downk.cc/item/5e62143798271cb2b81c8849.jpg)

出现这种情况的原因在于，当我们从S->B->C的时候，就已经走过了C，而更短的S->C->G因为我们希望不走重复路被排除了。

那么在图搜索中，$A^*$就会失效吗？可以挽救吗？

**答案是可以的**。

