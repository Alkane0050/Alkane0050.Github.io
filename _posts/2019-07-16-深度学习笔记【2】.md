---
layout:     post                    # 使用的布局（不需要改）
title:     深度学习笔记【2】          # 标题 
subtitle:   卷积神经网络CNN初步【原理篇】 #副标题
date:       2019-07-16            # 时间
author:     Alkane                      # 作者
header-img: img/post-bg-2015.jpg    #这篇文章标题背景图片
catalog: true                       # 是否归档
tags:                               #标签
    - 神经网络
---

# Two

前面我们认识了最基本的神经网络，也就是全连接神经网络，简写为DNN或是FNN。



这种神经网络已经能有很不错的功能了，并且通过简单的数学分析，我们可以证明：只需要一个隐含层，就可以拟合任意函数(满足**利普希兹条件**，也就是**光滑条件**)



但是，这样的神经网络并不是十全十美的，它也有不足和缺陷。之前一篇文章，我们见识了用DNN来识别手写图片，其中的图片的大小为$28\times 28\times1$ ，我们都没有使用隐含层，就有748个权重，10个偏置值需要训练。而现在，不管谁用手机随意拍一张照片，大小都远不止这个尺寸。如果你现在还坚守着十年前的手机，像素个数也超过百万量级了，放到今天动不动千万像素，照亮你的美，若是还使用之前的方法，是绝对不可行的，成本过高。



**那么是否可以减少需要训练的参数呢？**



## [卷积神经网络]([https://zh.wikipedia.org/wiki/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C](https://zh.wikipedia.org/wiki/卷积神经网络))兴起的背景

还是以识别图片为例子，以此我们来讨论卷积神经网络为什么有效，并且还能一窥大牛们的奇思妙想。



![](http://i1.go2yd.com/image.php?url=0LMXW5dMzX)



上面有一张图片，我们知道，图片是由许多像素点组成的，而像素点又是由三原色(RGB)构成的，每一个像素点都可以写成$[a,b,c]$这样的三元组，其中$0\le a,b,c \le 255$



因此，一张彩色图片就可以用一个三维张量(**tensor**)表示，所谓的张量，在机器学习领域，专指**高维矩阵**，不用太过在意。



如果用DNN的方法来做图像识别的话，那么以上面这张图片为例，上面这张图片大小为**640x360**，也就是需要$640\times 360\times 3=691200$,大约七十万个输入，这还不包括中间层，以及偏置值等需要训练的参数，而这张图片远远算不上高清的图片，如果要是换成比较大的图片，训练的难度立刻就要升一个数量级。



现在考虑一个情况，如果我们需要根据图片来识别人物，比如上面这张图中是灰原哀。如果上面的灰原哀不是处于图片的中间位置，而是处于图片的最右边呢？



按照DNN的方法，得到的输入是具有很大差异的，这可能就会带来神经网络的过学习问题，也就是说，即使我的设备非常的强，我能用最粗暴的方法来训练模型，但是我的模型却仍然有可能出现过学习的情况，不能在陌生的样本上有良好的表现。



在这样的问题下，卷积神经网络的想法诞生了。



视觉神经科学对于视觉机理的研究证明了大脑的视觉皮层具有分层结构。



眼睛看到的物体成像在视网膜上，视网膜把光信号转化成电信号，传递到大脑的视觉皮层。视觉皮层具有层次结构，从视网膜传来的信号首先到达初级视觉皮层(Primary Visual Cortex),即V1皮层，V1皮层的简单神经元对一些**细节、特定方向**的图像信号敏感。V1皮层处理之后，将信号传导到V2皮层。V2皮层将**边缘和轮廓信息**表示成简单现状，然后由V4皮层中的神经元进行处理，它**对颜色信息敏感**，复杂物体最终在IT皮层(Inferior Temporal  Cortex)被表示出来。



卷积神经网络可以看成是对这样的机制的简单模仿。其关键之处在于使用了**卷积**，提取了图片中的特定信息，并且这样的提取具有**平移不变性**。



下面我们来看一个例子。



## 一个卷积的例子



### Convolving

假设我们有一张图片，这张图片只使用灰度表示。同时，我们还有一个称作**卷积核**的矩阵。



![](https://victorzhou.com/media/cnn-post/convolve-example-1.svg)



如图，左边的就是我们的图片，右边就是一个卷积核。



那么卷积怎样作用于我们的图片呢？



下面用一张动图来描述这个过程：



![](https://victorzhou.com/convolve-output-69b4c1dd078ee363317bb8fa323eaace.gif)



不难看出，经过卷积运算后，原本$4\times 4$的图片，变成了$2\times 2$的图片，这其中，只不过使用了一个$3\times 3$的卷积核而已。



而卷积的运算，你可以明显的看出，就是对应位置的数字相乘再相加。

> 其实在数学或是信号处理领域，这并不是真正的卷积，而是所谓的**互相关**运算，因为这样的运算并不能满足：$A*(B*C)=A*B*C$,但是这并不妨碍我们使用它。因为在实际的神经网络训练中，所谓的互相关已经能够满足我们的需求了，并且在大多数的文献中，称这样的运算为卷积，所以我们在接下来的文章中也就沿用这一说法了。



这样的例子好像太小了，而且看不出什么用处，让我们再看一个更加明显的例子：



![](https://victorzhou.com/static/44a1ff59f9a2c7f62cf9f56a8398efd0/a8200/lenna%2Bvertical.png)



左边这张图，经过我们上面的卷积核，变成了右边的样子。可以看出，左边这张图中的垂直方向上的边缘特征，都被卷积核提取出来了，而且经过卷积后，虽然图像的信息变少了，但是变得更加**纯粹**，更加适合我们用于分类或是训练。



### Padding

还接着看这幅图



![](https://victorzhou.com/convolve-output-69b4c1dd078ee363317bb8fa323eaace.gif)



聪明的你是不是看出一些问题了？没错，你看，在中间的一些像素点，比如80、31等，都被所有的卷积核参与运算了，而边缘的像素点都只参与过一次运算，这样会不会导致**图像的边缘信息损失过多**呢？



再看一个问题，如果我们经过一连串的卷积运算后，原来图片的大小就会变得小很多，这样会不会导致原本分散开的信息像拧麻花一样都到一起了呢？并且图片大小小太多也会造成信息的丢失。



在这些问题的面前，聪明的先驱们想到了一个好主意，那就是给图像增加一圈，也就是让原本的边缘变得靠近中央，这样可以保证边缘信息丢失不太多，而图像大小也缩水不太多，**皆大欢喜**。



这个过程，我们称之为**Padding**:



![](http://www.elecfans.com/uploads/allimg/171115/1Z235V45_0.gif)



当然，有的时候，我们并不会一格一格的挪，就像跳格子一样，步子迈的大一点：



![](http://www.elecfans.com/uploads/allimg/171115/1Z201X22_0.gif)

这个过程称为**Striding**.



### Pooling

好了，现在到了卷积神经网络所有基本操作中的最后一种，**池化**，为什么叫这个名字，我其实不太懂，但是这个操作其实非常的简单。



有一个形象的例子，可以看一下这个[视频](<https://v.vzuu.com/video/1019541860720705536?>),虽然其中的方法并不是严格意义上的Pooling，但是和Pooling具有异曲同工之妙。



通俗的说，Pooling就是更好的提取特征，并且能够保证平移不变性。



下图的Pooling，是最常用的Pooling，也叫做**MaxPooling**



![](https://victorzhou.com/pool-ac441205fd06dc037b3db2dbf05660f7.gif)





## 具体的卷积神经网络结构

上述操作的目的都是相同的，就是使得我们的神经网络训练变得更加的容易和轻松。



首先来看一下一个简单的卷积神经网络结构：



以手写数字识别的问题为例：



![](https://victorzhou.com/media/cnn-post/cnn-dims-3.svg)



输入为$28\times 28$的图片，输出为一个十维向量，其中最大的分量意味着该位置上的类别具有最大可能为图片的类别。



首先，图片经过一个$3\times 3$的**卷积层**，变为$26\times 26\times 8$的张量。



> 也许有人要问，为什么变成26x26x8的张量？
>
> 这是因为，在图像中，如果只使用一个卷积核，往往提取的信息是很少部分的，我们需要多个卷积核，才能有把握的提取出我们需要的信息。



接着，卷积层输出到**池化层**，将$26\times 26\times 8$的张量变成$13\times 13\times 8$的张量。



最后，通过将池化层的输出**展平**，将其变成1352维的向量，充当**全连接神经网络的输入层**输入到softmax函数中，得到预测的结果。



接着**采用交叉熵作为损失函数**，使用反向传播算法来训练模型。



到这里，可能有人会问：为什么使用卷积神经网络，好像带来了更多的参数？



我的回答是：你说的对，但也不全对。



在这个例子中，参数分别有：

- 8个$3\times 3$的卷积核，共计72个参数
- 池化层没有参数
- 池化层的输出作为全连接神经网络的输入层输入到softmax中，共有十个类别，共计$1352\times 10+10=13530$个参数

一共有**13602个参数**需要训练，而之前的全连接神经网络共有$748\times 10+10=7490$个参数需要训练。



但是，之前的全连接神经网络不仅没有隐含层，而且它的训练结果只能用于28x28的图片，如果我们改变图片的大小，那么它就要再次训练。



而卷积神经网络训练的最主要的是它的**卷积核**，因为卷积核起到的作用是**提取特征**，很多特征无法让人类直接说出来，这个时候，经过训练的卷积神经网络，能够有效的提取出最关键的图像特征。最为高效的是，这样的卷积核不仅适用于原本的样本，放到更大的图片中一样适用！

## 参考

[Victor Zhou的博文](<https://victorzhou.com/blog/intro-to-cnns-part-1/>)

图片来自网络，来源见水印，无水印的图片大多来自周先生的博文。