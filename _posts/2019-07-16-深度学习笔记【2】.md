---
layout:     post                    # 使用的布局（不需要改）
title:     深度学习笔记【2】          # 标题 
subtitle:   卷积神经网络CNN初步【原理篇】 #副标题
date:       2019-07-16            # 时间
author:     Alkane                      # 作者
header-img: img/post-bg-2015.jpg    #这篇文章标题背景图片
catalog: true                       # 是否归档
tags:                               #标签
    - 神经网络
---

# Two

前面我们认识了最基本的神经网络，也就是全连接神经网络，简写为DNN或是FNN。



这种神经网络已经能有很不错的功能了，并且通过简单的数学分析，我们可以证明：只需要一个隐含层，就可以拟合任意函数(满足**利普希兹条件**，也就是**光滑条件**)



但是，这样的神经网络并不是十全十美的，它也有不足和缺陷。之前一篇文章，我们见识了用DNN来识别手写图片，其中的图片的大小为$28\times 28\times1$ ，我们都没有使用隐含层，就有748个权重，10个偏置值需要训练。而现在，不管谁用手机随意拍一张照片，大小都远不止这个尺寸。如果你现在还坚守着十年前的手机，像素个数也超过百万量级了，放到今天动不动千万像素，照亮你的美，若是还使用之前的方法，是绝对不可行的，成本过高。



**那么是否可以减少需要训练的参数呢？**



## 卷积神经网络兴起的背景

还是以识别图片为例子，以此我们来讨论卷积神经网络为什么有效，并且还能一窥大牛们的奇思妙想。



![](http://i1.go2yd.com/image.php?url=0LMXW5dMzX)



上面有一张图片，我们知道，图片是由许多像素点组成的，而像素点又是由三原色(RGB)构成的，每一个像素点都可以写成$[a,b,c]$这样的三元组，其中$0\le a,b,c \le 255$



因此，一张彩色图片就可以用一个三维张量(**tensor**)表示，所谓的张量，在机器学习领域，专指**高维矩阵**，不用太过在意。



如果用DNN的方法来做图像识别的话，那么以上面这张图片为例，上面这张图片大小为**640x360**，也就是需要$640\times 360\times 3=691200$,大约七十万个输入，这还不包括中间层，以及偏置值等需要训练的参数，而这张图片远远算不上高清的图片，如果要是换成比较大的图片，训练的难度立刻就要升一个数量级。



现在考虑一个情况，如果我们需要根据图片来识别人物，比如上面这张图中是灰原哀。如果上面的灰原哀不是处于图片的中间位置，而是处于图片的最右边呢？



按照DNN的方法，得到的输入是具有很大差异的，这可能就会带来神经网络的过学习问题，也就是说，即使我的设备非常的强，我能用最粗暴的方法来训练模型，但是我的模型却仍然有可能出现过学习的情况，不能在陌生的样本上有良好的表现。



在这样的问题下，卷积神经网络的想法诞生了。



视觉神经科学对于视觉机理的研究证明了大脑的视觉皮层具有分层结构。



眼睛看到的物体成像在视网膜上，视网膜把光信号转化成电信号，传递到大脑的视觉皮层。视觉皮层具有层次结构，从视网膜传来的信号首先到达初级视觉皮层(Primary Visual Cortex),即V1皮层，V1皮层的简单神经元对一些**细节、特定方向**的图像信号敏感。V1皮层处理之后，将信号传导到V2皮层。V2皮层将**边缘和轮廓信息**表示成简单现状，然后由V4皮层中的神经元进行处理，它**对颜色信息敏感**，复杂物体最终在IT皮层(Inferior Temporal  Cortex)被表示出来。



卷积神经网络可以看成是对这样的机制的简单模仿。其关键之处在于使用了**卷积**，提取了图片中的特定信息，并且这样的提取具有**平移不变性**。



下面我们来看一个例子。



## 一个卷积的例子



### Convolving

假设我们有一张图片，这张图片只使用灰度表示。同时，我们还有一个称作**卷积核**的矩阵。



![](https://victorzhou.com/media/cnn-post/convolve-example-1.svg)



如图，左边的就是我们的图片，右边就是一个卷积核。



那么卷积怎样作用于我们的图片呢？



下面用一张动图来描述这个过程：



![](https://victorzhou.com/convolve-output-69b4c1dd078ee363317bb8fa323eaace.gif)



不难看出，经过卷积运算后，原本$4\times 4$的图片，变成了$2\times 2$的图片，这其中，只不过使用了一个$3\times 3$的卷积核而已。



而卷积的运算，你可以明显的看出，就是对应位置的数字相乘再相加。

> 其实在数学或是信号处理领域，这并不是真正的卷积，而是所谓的**互相关**运算，因为这样的运算并不能满足：$A*(B*C)=A*B*C$,但是这并不妨碍我们使用它。因为在实际的神经网络训练中，所谓的互相关已经能够满足我们的需求了，并且在大多数的文献中，称这样的运算为卷积，所以我们在接下来的文章中也就沿用这一说法了。



这样的例子好像太小了，而且看不出什么用处，让我们再看一个更加明显的例子：



![](https://victorzhou.com/static/44a1ff59f9a2c7f62cf9f56a8398efd0/a8200/lenna%2Bvertical.png)



左边这张图，经过我们上面的卷积核，变成了右边的样子。可以看出，左边这张图中的垂直方向上的边缘特征，都被卷积核提取出来了，而且经过卷积后，虽然图像的信息变少了，但是变得更加**纯粹**，更加适合我们用于分类或是训练。



### Padding

还接着看这幅图



![](https://victorzhou.com/convolve-output-69b4c1dd078ee363317bb8fa323eaace.gif)



聪明的你是不是看出一些问题了？没错，你看，在中间的一些像素点，比如80、31等，都被所有的卷积核参与运算了，而边缘的像素点都只参与过一次运算，这样会不会导致**图像的边缘信息损失过多**呢？



再看一个问题，如果我们经过一连串的卷积运算后，原来图片的大小就会变得小很多，这样会不会导致原本分散开的信息像拧麻花一样都到一起了呢？并且图片大小小太多也会造成信息的丢失。



在这些问题的面前，聪明的先驱们想到了一个好主意，那就是给图像增加一圈，也就是让原本的边缘变得靠近中央，这样可以保证边缘信息丢失不太多，而图像大小也缩水不太多，**皆大欢喜**。



这个过程，我们称之为**Padding**:



![](http://www.elecfans.com/uploads/allimg/171115/1Z235V45_0.gif)



当然，有的时候，我们并不会一格一格的挪，就像跳格子一样，步子迈的大一点：



![](http://www.elecfans.com/uploads/allimg/171115/1Z201X22_0.gif)

这个过程称为**Striding**.



### Pooling

好了，现在到了卷积神经网络所有基本操作中的最后一种，**池化**，为什么叫这个名字，我其实不太懂，但是这个操作其实非常的简单。



<video src="2019-07-16-深度学习笔记【2】.assets/7ed262b0-ae5d-11e8-956e-0242ac112a0a.mp4"></video>